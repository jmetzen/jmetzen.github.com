<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
      <title>Cur­ricu­lum vi­tae</title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
        <link rel="stylesheet" href="stylesheets/style.css">
    </head>
<body>
  <header itemscope itemtype="http://http://schema.org/Person" class="with-photo">
    <div id="title" class="">
            <h1 class="fullname">
        <span itemprop="givenName">Jan Hendrik</span>
        <span itemprop="familyName">Metzen</span>
      </h1>
      <h2 class="title">Cur­ricu­lum vi­tae</h2>
    </div>
        <img src="images/picture.jpg" />
        <ul class="details">
      <!-- phone -->
                        <li><a class='phone' href="phoneto:+49-(421)-218-45-4123">+49-(421)-218-45-4123</a></li>
                        <!-- mobile -->
            <!-- fax -->
            <!-- email -->
                        <li><a href="mailto:jhm@informatik.uni-bremen.de">jhm@informatik.uni-bremen.de</a></li>
                        <!-- homepage -->
            <li><a href="http://www.informatik.uni-bremen.de/~jhm/" itemprop="url" title="homepage">http://www.informatik.uni-bremen.de/~jhm/</a></li>
            <!--if(address)-->
            <!--endif-->
    </ul>
  </header>

  
  <section id="research" class="level2">
  <h2>Research</h2>
  <dl>
  <dt>Reinforcement Learning</dt>
  <dd><p>Working on developing new means for skill discovery and learning of motor primitives and combining those in a Hierarchical Reinforment Learning approach. Developed the graph-based skill discovery method <a href="http://www.informatik.uni-bremen.de/~jhm/publications/b2hd-MetzenEWRL2012OGAHC.html">OGAHC</a>. Furthermore, we are developing an integrated experimental platform, the <a href="http://mmlf.sourceforge.net/">Maja Machine Learning Framework (MMLF)</a>, which simplifies empirical evaluations in Reinforcement Learning. This work is part of the <a href="http://robotik.dfki-bremen.de/en/research/projects/besman-1.html">BesMan</a> project. <a href="http://www.informatik.uni-bremen.de/~jhm/publications/class_rescat.html#Reinforcement%20Learning">Relevant publications</a></p>
  </dd>
  <dt>BCIs</dt>
  <dd><p><strong>Brain Computer Interface</strong>: We use supervised machine learning techniques to detect event-related potentials (ERPs) in a human’s electroencephalogram (EEG) that indicate that the human has perceived and recognized important messages that have been presented to him or that he intends to execute a movement shortly. My work in the VI-Bot and IMMI project was focused mainly on investigating how the system can detect these ERPs with a minimum amount of labeled training data from the current user by reusing data from historic sessions of the same and other users. <a href="http://www.informatik.uni-bremen.de/~jhm/publications/class_rescat.html#Brain%20Computer%20Interface">Relevant publications</a></p>
  </dd>
  </dl>
  <p>See also my <a href="http://scholar.google.com/citations?user=w047VfEAAAAJ&amp;hl=en">Google Scholar page</a></p>
  </section>
  <section id="positions" class="level2">
  <h2>Positions</h2>
  <dl>
  <dt>2014 -</dt>
  <dd><p>Project leader <a href="http://robotik.dfki-bremen.de/en/research/projects/cascade.html">“CASCADE: Cognitive AutonomouS CAtheters operating in Dynamic Environments”</a>,<br /> Robotics Research Group, University Bremen</p>
  </dd>
  <dt>2013 -</dt>
  <dd><p>Team leader <a href="http://robotik.dfki-bremen.de/en/research/teams.html#c1585">“Sustained Learning”</a>,<br /> Robotics Innovation Center, German Research Center for Artificial Intelligence (DFKI RIC, Bremen)</p>
  </dd>
  <dt>2008 -</dt>
  <dd><p>Organizer of workgroup “Machine Learning and Optimization”<br /> Robotics Research Group, University Bremen</p>
  </dd>
  <dt>2009 -</dt>
  <dd><p>Research assistant<br /> Robotics Research Group, University of Bremen</p>
  </dd>
  <dt>2007 - 2009</dt>
  <dd><p>Researcher<br /> Robotics Innovation Center, German Research Center for Artificial Intelligence (DFKI RIC, Bremen)</p>
  </dd>
  <dt>2006 - 2007</dt>
  <dd><p>Research assistant<br /> Robotics Research Group, University of Bremen</p>
  </dd>
  </dl>
  </section>
  <section id="education" class="level2">
  <h2>Education</h2>
  <dl>
  <dt>2009 - 2013</dt>
  <dd><p><strong>Dr.rer.nat.</strong>, University Bremen, Germany<br /> Thesis title <a href="http://www.informatik.uni-bremen.de/~jhm/publications/metzen_learning_2014.pdf">“Learning the Structure of Continuous Markov Decision Processes”</a></p>
  </dd>
  <dt>2001 - 2006</dt>
  <dd><p><strong>Diploma</strong> in Computer Science, University Münster, Germany<br /> Thesis title <a href="http://www.informatik.uni-bremen.de/~jhm/publications/MetzenDA2006.pdf">“Matching von Baumstrukturen in der medizinischen Bildverarbeitung”</a></p>
  </dd>
  </dl>
  </section>
  <section id="awards-and-grants" class="level2">
  <h2>Awards and Grants</h2>
  <dl>
  <dt>2004 - 2006</dt>
  <dd><strong>Scholarship</strong> of “Studienstiftung des Deutschen Volkes” (German National Academic Foundation)
  </dd>
  </dl>
  </section>
  <section id="publications" class="level2">
  <h2>Publications</h2>
  <p>You can find a list of my publications on my <a href="http://www.informatik.uni-bremen.de/~jhm/publications/class_type.html">official website</a></p>
  </section>
  <section id="teaching" class="level2">
  <h2>Teaching</h2>
  <dl>
  <dt>WS 2014</dt>
  <dd><p><a href="http://robotik.dfki-bremen.de/de/lehre/lehrveranstaltungen/vergangene-semester/wintersemester-201415.html">Lernverfahren für autonome Roboter</a></p>
  </dd>
  <dt>SS 2014</dt>
  <dd><p><a href="http://robotik.dfki-bremen.de/de/lehre/lehrveranstaltungen/vergangene-semester/sommersemester-2014.html">Reinforcement Lernen</a></p>
  </dd>
  <dt>WS 2013</dt>
  <dd><p><a href="http://robotik.dfki-bremen.de/de/lehre/lehrveranstaltungen/vergangene-semester/wintersemester-201314.html">Lernverfahren für autonome Roboter</a></p>
  </dd>
  <dt>SS 2013</dt>
  <dd><p><a href="http://robotik.dfki-bremen.de/de/lehre/lehrveranstaltungen/vergangene-semester/sommersemester-2013.html">Reinforcement Lernen</a></p>
  </dd>
  <dt>WS 2012</dt>
  <dd><p><a href="http://robotik.dfki-bremen.de/de/lehre/lehrveranstaltungen/vergangene-semester/wintersemester-201213.html">Lernverfahren für autonome Roboter</a></p>
  </dd>
  <dt>SS 2012</dt>
  <dd><p>Reinforcement Lernen</p>
  </dd>
  <dt>WS 2012</dt>
  <dd><p>Lernverfahren für autonome Roboter</p>
  </dd>
  <dt>SS 2011</dt>
  <dd><p>Reinforcement Lernen</p>
  </dd>
  <dt>WS 2011</dt>
  <dd><p>Maschinelles Lernen für autonome Roboter 2</p>
  </dd>
  <dt>SS 2010</dt>
  <dd><p>Maschinelles Lernen für autonome Roboter 1</p>
  </dd>
  <dt>WS 2010</dt>
  <dd><p>Maschinelles Lernen für autonome Roboter 2</p>
  </dd>
  </dl>
  </section>
  <section id="open-source-software" class="level2">
  <h2>Open Source Software</h2>
  <dl>
  <dt>MMLF</dt>
  <dd><p>The <a href="http://mmlf.sourceforge.net/">Maja Machine Learning Framework (MMLF)</a> is a general framework for problems in the domain of Reinforcement Learning (RL) written in python. It provides a set of RL related algorithms and a set of benchmark domains. Furthermore it is easily extensible and allows to automate benchmarking of different agents. Among the RL algorithms are TD(lambda), CMA-ES, Fitted R-Max, Monte-Carlo learning, the DYNA-TD and the actor-critic architecture. MMLF contains different variants of the maze-world and pole-balancing problem class as well as the mountain-car testbed and the pinball maze domain.</p>
  </dd>
  <dt>pySPACE</dt>
  <dd><p><a href="http://pyspace.github.io/pyspace/">pySPACE</a> is a Signal Processing And Classification Environment (SPACE) written in Python interfacing to the user with YAML configuration files and enabling parallel process execution. pySPACE allows rapid specification, execution, and analysis of empirical investigations (short: benchmarking) in signal processing and machine learning. Besides the benchmarking way of executing pySPACE where you can evaluate your data with your own configuration of algorithms, the software also provides an on-line mode where you can directly execute signal processing as soon as you have the data in an on-line fashion. For more information, please refer to our <a href="http://www.frontiersin.org/neuroinformatics/10.3389/fninf.2013.00040/abstract">paper</a> published in the research topic “Python in Neuroscience II” in the Frontiers in Neuroinformatics journal.</p>
  </dd>
  </dl>
  </section>
  <section id="community" class="level2">
  <h2>Community</h2>
  <dl>
  <dt>2014</dt>
  <dd><p>Reviewer of the <a href="http://www.nature.com/srep/index.html">Scientific Reports</a> journal of the Nature publisher</p>
  </dd>
  <dt>2013</dt>
  <dd><p>Reviewer of the <a href="http://www.frontiersin.org/Cognitive_Science">Frontiers in Cognitive Science</a> journal</p>
  </dd>
  <dt>2013-2014</dt>
  <dd><p>Reviewer of the <a href="http://jmlr.org/">Journal of Machine Learning Research (JMLR)</a></p>
  </dd>
  <dt>2012</dt>
  <dd><p>Program committee of 5th International Workshop on Evolutionary and Reinforcement Learning for Autonomous Robot Systems (<a href="http://www.erlars.org/2012/">ERLARS 2012</a>)</p>
  </dd>
  <dt>2009</dt>
  <dd><p>Reviewer of the <a href="http://www.journals.elsevier.com/image-and-vision-computing/">Image and Vision Computing Journal (IVC)</a></p>
  </dd>
  </dl>
  </section>

  
  <footer>
    <ul>
    <li><a href="http://github.com/jmetzen">jmetzen</a></li>
    </ul>
      </footer>
</body>
</html>