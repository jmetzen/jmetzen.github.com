<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<title>Jan Hendrik Metzen:  Analysis of an evolutionary reinforcement learning method in a multiagent domain</title>
<link rel="StyleSheet" href="../pfrstyle.css" type="text/css">
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
</head>
<body>
<h1>Jan Hendrik Metzen's Publications</h1>
<p><big>&#8226;
  <a href="sort_default.html">Default Ordering</a> &#8226;
  <a href="sort_date.html">Sorted by Date</a> &#8226;
  <a href="class_type.html">Classified by Publication Type</a> &#8226;
  <a href="class_rescat.html">Classified by Research Category</a> &#8226;
  </big></p>
<h2> Analysis of an evolutionary reinforcement learning method in a multiagent domain</h2>
<p class="citation"><a href="http://www.informatik.uni-bremen.de/~jhm/"> Jan Hendrik Metzen</a>,  Mark Edgington,  Yohannes Kassahun, and  Frank Kirchner.  Analysis of an evolutionary reinforcement learning method in a multiagent domain. In <i> Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems</i>, pp. 291&ndash;298,  AAMAS '08,  International Foundation for Autonomous Agents and Multiagent Systems,  Richland, SC, May 2008.</p>
<h3>Download</h3>
<p><a href="http://portal.acm.org/citation.cfm?id=1402428">[HTML]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract"> Many multiagent problems comprise subtasks which can be considered as reinforcement learning (RL) problems. In addition to classical temporal difference methods, evolutionary algorithms are among the most  promising approaches for such RL problems. The relative performance of these approaches in certain subdomains (e.g. multiagent learning) of the general RL problem remains an open question at this time. In addition to theoretical analysis, benchmarks are one of the most important tools for comparing different RL methods in certain problem domains. A recently proposed multiagent RL benchmark problem is the RoboCup Keepaway benchmark. This benchmark is one of the most challenging multiagent learning problems because its state-space is continuous and high dimensional, and both the sensors and the actuators are noisy.  In this paper we analyze the performance of the neuroevolutionary approach called Evolutionary Acquisition of Neural Topologies (EANT) in the Keepaway benchmark, and compare the results obtained using EANT with the results of other algorithms tested on the same benchmark.</p>
<a href="MetzenAAMAS2008.bib"><h3>BibTeX</h3></a><pre>@inproceedings{Metzen:AAMAS:2008,
	address = {Richland, {SC}},
	title = {Analysis of an evolutionary reinforcement learning method in a multiagent domain},
	isbn = {978-0-9817381-0-9},
	location = {Estoril, Portugal},
	url = {http://portal.acm.org/citation.cfm?id=1402428},
	series = {{AAMAS} '08},
	booktitle = {Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Jan Hendrik Metzen and Mark Edgington and Yohannes Kassahun and Frank Kirchner},
	month = may,
	year = {2008},
	pages = {291--298},
        abstract = {Many multiagent problems comprise subtasks which can be considered as reinforcement learning (RL) problems. In addition to classical temporal difference methods, evolutionary algorithms are among the most  promising approaches for such RL problems. The relative performance of these approaches in certain subdomains (e.\,g. multiagent learning) of the general RL problem remains an open question at this time. In addition to theoretical analysis, benchmarks are one of the most important tools for comparing different RL methods in certain problem domains. A recently proposed multiagent RL benchmark problem is the RoboCup Keepaway benchmark. This benchmark is one of the most challenging multiagent learning problems because its state-space is continuous and high dimensional, and both the sensors and the actuators are noisy.  In this paper we analyze the performance of the neuroevolutionary approach called Evolutionary Acquisition of Neural Topologies (EANT) in the Keepaway benchmark, and compare the results obtained using EANT with the results of other algorithms tested on the same benchmark.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution, Reinforcement Learning}
}
</pre>
<hr width="100%" size="2">
<p><small>
 Generated by
 <a href="https://sourceforge.net/projects/bib2html/">bib2html.pl</a>
 (written by <a href="http://sourceforge.net/users/patstg/">Patrick Riley</a>
  ) on
  Sun Nov 27, 2016 21:02:02</small></p>
</body>
</html>
