<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<title>Jan Hendrik Metzen:  Learning the Structure of Continuous Markov Decision Processes</title>
<link rel="StyleSheet" href="../pfrstyle.css" type="text/css">
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
</head>
<body>
<h1>Jan Hendrik Metzen's Publications</h1>
<p><big>&#8226;
  <a href="sort_default.html">Default Ordering</a> &#8226;
  <a href="sort_date.html">Sorted by Date</a> &#8226;
  <a href="class_type.html">Classified by Publication Type</a> &#8226;
  <a href="class_rescat.html">Classified by Research Category</a> &#8226;
  </big></p>
<h2> Learning the Structure of Continuous Markov Decision Processes</h2>
<p class="citation"><a href="http://www.informatik.uni-bremen.de/~jhm/"> Jan Hendrik Metzen</a>.  Learning the Structure of Continuous Markov Decision Processes. Ph.D. Thesis,  Universit&auml;t Bremen,  Bremen, 2014.</p>
<h3>Download</h3>
<p><a href="./metzen_learning_2014.pdf">[PDF]13.9MB
  </a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract"> There is growing interest in artificial, intelligent agents which can operate autonomously for an extended period of time in complex environments and fulfill a variety of different tasks. Such agents will face different problems during their lifetime which may not be foreseeable at the time of their deployment. Thus, the capacity for lifelong learning of new behaviors is an essential prerequisite for this kind of agents as it enables them to deal with unforeseen situations.However, learning every complex behavior anew from scratch would be cumbersome for the agent. It is more plausible to consider behavior to be modular and let the agent acquire a set of reusable building blocks for behavior, the so-called skills. These skills might, once acquired, facilitate fast learning and adaptation of behavior to new situations. This work focuses on computational approaches for skill acquisition, namely which kind of skills shall be acquired and how to acquire them. The former is commonly denoted as "skill discovery" and the latter as "skill learning".The main contribution of this thesis is a novel incremental skill acquisition approach which is suited for lifelong learning. In this approach, the agent learns incrementally a graph-based representation of a domain and exploits certain properties of this graph such as its bottlenecks for skill discovery. This thesis proposes a novel approach for learning a graph-based representation of continuous domains based on formalizing the problem as a probabilistic generative model. Furthermore, a new incremental agglomerative clustering approach for identifying bottlenecks of such graphs is presented.Thereupon, the thesis proposes a novel intrinsic motivation system which enables an agent to intelligently allocate time between skill discovery and skill learning in developmental settings, where the agent is not constrained by external tasks. The results of this thesis show that the resulting skill acquisition approach is suited for continuous domains and can deal with domain stochasticity and different explorative behavior of the agent. The acquired skills are reusable and versatile and can be used in multi-task and lifelong learning settings in high-dimensional problems.</p>
<a href="metzen_learning_2014.bib"><h3>BibTeX</h3></a><pre>@phdthesis{metzen_learning_2014,
	address = {Bremen},
	type = {{PhD} Thesis},
	title = {Learning the Structure of Continuous Markov Decision Processes},
	url = {http://nbn-resolving.de/urn:nbn:de:gbv:46-00103656-17},
	abstract = {There is growing interest in artificial, intelligent agents which can operate autonomously for an extended period of time in complex environments and fulfill a variety of different tasks. Such agents will face different problems during their lifetime which may not be foreseeable at the time of their deployment. Thus, the capacity for lifelong learning of new behaviors is an essential prerequisite for this kind of agents as it enables them to deal with unforeseen situations.
However, learning every complex behavior anew from scratch would be cumbersome for the agent. It is more plausible to consider behavior to be modular and let the agent acquire a set of reusable building blocks for behavior, the so-called skills. These skills might, once acquired, facilitate fast learning and adaptation of behavior to new situations. This work focuses on computational approaches for skill acquisition, namely which kind of skills shall be acquired and how to acquire them. The former is commonly denoted as "skill discovery" and the latter as "skill learning".
The main contribution of this thesis is a novel incremental skill acquisition approach which is suited for lifelong learning. In this approach, the agent learns incrementally a graph-based representation of a domain and exploits certain properties of this graph such as its bottlenecks for skill discovery. This thesis proposes a novel approach for learning a graph-based representation of continuous domains based on formalizing the problem as a probabilistic generative model. Furthermore, a new incremental agglomerative clustering approach for identifying bottlenecks of such graphs is presented.
Thereupon, the thesis proposes a novel intrinsic motivation system which enables an agent to intelligently allocate time between skill discovery and skill learning in developmental settings, where the agent is not constrained by external tasks. The results of this thesis show that the resulting skill acquisition approach is suited for continuous domains and can deal with domain stochasticity and different explorative behavior of the agent. The acquired skills are reusable and versatile and can be used in multi-task and lifelong learning settings in high-dimensional problems.},
	language = {English},
	school = {Universit{\"a}t Bremen},
	author = {Metzen, Jan Hendrik},
	year = {2014},
	keywords = {graph, hierarchical-rl, motivation, reinforcement-learning, skill-discovery},
        bib2html_pubtype = {Thesis},
        bib2html_rescat = {Reinforcement Learning},
        Local-Url = "../files/phd_thesis.pdf"
}
</pre>
<hr width="100%" size="2">
<p><small>
 Generated by
 <a href="https://sourceforge.net/projects/bib2html/">bib2html.pl</a>
 (written by <a href="http://sourceforge.net/users/patstg/">Patrick Riley</a>
  ) on
  Mon May 01, 2017 19:36:28</small></p>
</body>
</html>
